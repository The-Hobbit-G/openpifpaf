#!/bin/bash -l

#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=10
#SBATCH --mem=48G
#SBATCH --partition=gpu
#SBATCH --qos=gpu
#SBATCH --gres=gpu:1
#SBATCH --time=01:00:00
#SBATCH --output=/scratch/izar/<username>/<path/to/dir>/%x.out

shopt -s extglob


echo STARTING AT `date`


evalxp='opp_train_resnet50'
evalepoch=150


xpdir="/scratch/izar/<username>/<path/to/dir>/${SLURM_JOB_NAME}"

mkdir -p ${xpdir}
mkdir -p ${xpdir}/code
tar -czvf ${xpdir}/code/code.tar.gz <path/to/code/dir>
mkdir -p ${xpdir}/logs


cd ..

mkdir -p ${xpdir}/predictions

for cpepoch in ${evalepoch}
do
  evalfrom="/scratch/izar/<username>/<path/to/dir>/${evalxp}/checkpoints/${evalxp}.pt.epoch${cpepoch}"
  echo "Start evaluating ${evalfrom}..."
  srun time python3 -m openpifpaf.eval \
    --write-predictions \
    --output ${xpdir}/predictions/${SLURM_JOB_NAME}_epoch${cpepoch} \
    --dataset=cocokp \
    --coco-eval-long-edge 641 \
    --cocokp-upsample=2 \
    --coco-no-eval-annotation-filter \
    --batch-size 1 \
    --loader-workers 8 \
    --checkpoint ${evalfrom} \
    --decoder=cifcaf:0 \
    --seed-threshold 0.2 \
    --force-complete-pose \
    2>&1 | tee ${xpdir}/logs/${SLURM_JOB_NAME}_epoch${cpepoch}.log
  echo "Done evaluating ${evalfrom}"
done

cd -


echo FINISHED at `date`
